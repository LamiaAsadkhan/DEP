{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "fSc3vELN6kIU"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load your dataset\n",
        "train_data = pd.read_csv('twitter_training.csv')\n",
        "validation_data = pd.read_csv('twitter_validation.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "# Check the types of the values in the 'text' column\n",
        "print(train_data['text'].apply(type).value_counts())\n",
        "\n",
        "# Optionally, handle non-string values (convert to empty string or drop rows)\n",
        "train_data['text'] = train_data['text'].astype(str)\n",
        "validation_data['text'] = validation_data['text'].astype(str)\n",
        "def preprocess(text):\n",
        "    # Remove special characters and links\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    text = re.sub(r'\\@\\w+|\\#', '', text)\n",
        "\n",
        "    # Tokenization\n",
        "    tokens = word_tokenize(text)\n",
        "\n",
        "    # Lowercasing and removing stop words\n",
        "    tokens = [word.lower() for word in tokens if word.isalpha()]\n",
        "    tokens = [word for word in tokens if not word in stopwords.words('english')]\n",
        "\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "train_data['clean_text'] = train_data['text'].apply(preprocess)\n",
        "validation_data['clean_text'] = validation_data['text'].apply(preprocess)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC8jbT2-7CMs",
        "outputId": "0c9f79a7-c14a-4c14-be58-4b3b4d60a05c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text\n",
            "<class 'str'>      73995\n",
            "<class 'float'>      686\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_data[['clean_text']].head())\n",
        "print(validation_data[['clean_text']].head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RgHsu1S7W9I",
        "outputId": "c6d273fc-b081-45aa-addf-d5139efa1ee6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                      clean_text\n",
            "0            coming borders kill\n",
            "1    im getting borderlands kill\n",
            "2   im coming borderlands murder\n",
            "3  im getting borderlands murder\n",
            "4  im getting borderlands murder\n",
            "                                          clean_text\n",
            "0  bbc news amazon boss jeff bezos rejects claims...\n",
            "1               pay word functions poorly chromebook\n",
            "2  csgo matchmaking full closet hacking truly awf...\n",
            "3  president slapping americans face really commi...\n",
            "4  hi madeleine mccann cellar past years little s...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# Initialize the TF-IDF Vectorizer\n",
        "vectorizer = TfidfVectorizer(max_features=5000)  # Limit features to 5000 for simplicity\n",
        "\n",
        "# Fit and transform the training data\n",
        "X_train = vectorizer.fit_transform(train_data['clean_text'])\n",
        "y_train = train_data['type']\n",
        "\n",
        "# Transform the validation data\n",
        "X_valid = vectorizer.transform(validation_data['clean_text'])\n",
        "y_valid = validation_data['type']\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wgNL2NfRBi4N"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "source": [
        "# Initialize the Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)  # Increase iterations if needed\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train)\n"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        },
        "id": "A53TDmL2C0MU",
        "outputId": "a0fbc3bd-cc40-4caf-a1b9-3ef6de6535ed"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict the sentiments on the validation set\n",
        "y_pred = model.predict(X_valid)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_valid, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Detailed classification report\n",
        "print(classification_report(y_valid, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDso-flEI4yj",
        "outputId": "dbbdc978-9f04-4724-882a-5dc03bbc690e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.81\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  Irrelevant       0.82      0.68      0.75       171\n",
            "    Negative       0.75      0.86      0.80       266\n",
            "     Neutral       0.84      0.78      0.81       285\n",
            "    Positive       0.83      0.86      0.84       277\n",
            "\n",
            "    accuracy                           0.81       999\n",
            "   macro avg       0.81      0.79      0.80       999\n",
            "weighted avg       0.81      0.81      0.80       999\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MkKaSuSPJA3J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}